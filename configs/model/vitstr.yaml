name: vitstr
_target_: strhub.models.vitstr.system.ViTSTR

# Data
img_size: [ 224, 224 ]  # [ height, width ]
patch_size: [ 16, 16 ]  # [ height, width ]

# Architecture
embed_dim: 384
num_heads: 6

# Training
lr: 8.9e-4

# https://github.com/rwightman/pytorch-image-models/blob/main/timm/models/vision_transformer.py
# imagenet21k_pretrained: B_16-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.0-sd_0.0.pth
